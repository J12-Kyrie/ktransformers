# DeepSeek-V3-0324-GGUF-Q4_K_M ????????

## ????????

????????????????

### ? ???????
1. **GGUF ????**?9???????
   - DeepSeek-V3-0324-Q4_k_m-00001-of-00009.gguf
   - DeepSeek-V3-0324-Q4_k_m-00002-of-00009.gguf
   - DeepSeek-V3-0324-Q4_k_m-00003-of-00009.gguf
   - DeepSeek-V3-0324-Q4_k_m-00004-of-00009.gguf
   - DeepSeek-V3-0324-Q4_k_m-00005-of-00009.gguf
   - DeepSeek-V3-0324-Q4_k_m-00006-of-00009.gguf
   - DeepSeek-V3-0324-Q4_k_m-00007-of-00009.gguf
   - DeepSeek-V3-0324-Q4_k_m-00008-of-00009.gguf
   - DeepSeek-V3-0324-Q4_k_m-00009-of-00009.gguf

2. **????**?
   - configuration.json ?

### ? ??????

**?? Tokenizer ????**?????

?? `ktransformers/local_chat.py` ? `kt-kernel/scripts/convert_weights.py` ?????????????? tokenizer ???

1. **tokenizer.json** - Tokenizer ??????????
2. **tokenizer_config.json** - Tokenizer ????????
3. **special_tokens_map.json** - ?? token ??????

?????????
- vocab.json????? BPE tokenizer?
- merges.txt????? BPE tokenizer?
- tokenizer.model????? SentencePiece tokenizer?
- generation_config.json?????????

## ????

????????
- ? ???????GGUF ???
- ? ???????configuration.json?

?? **?? tokenizer ??**??????

1. **????????**??????????????????? token ID
2. **????????**????????? token ID ????????
3. **????????**?DeepSeek-V3 ? `apply_chat_template` ???? tokenizer

## ????

### ?? 1?? Hugging Face ??????

????????? tokenizer ???

```bash
# ??????? deepseek-ai/DeepSeek-V3
cd /path/to/DeepSeek-V3-0324-GGUF-Q4_K_M

# ?? huggingface-cli ??
huggingface-cli download deepseek-ai/DeepSeek-V3 \
    tokenizer.json \
    tokenizer_config.json \
    special_tokens_map.json \
    --local-dir . \
    --local-dir-use-symlinks False
```

### ?? 2??????????

??????? DeepSeek-V3 ??????? .safetensors ??????????????

```bash
cp /path/to/original/model/tokenizer.json .
cp /path/to/original/model/tokenizer_config.json .
cp /path/to/original/model/special_tokens_map.json .
```

### ?? 3??? Python ????

```python
from transformers import AutoTokenizer
import os

model_name = "deepseek-ai/DeepSeek-V3"  # ???????????
output_dir = "/path/to/DeepSeek-V3-0324-GGUF-Q4_K_M"

# ?? tokenizer
tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)

# ???????
tokenizer.save_pretrained(output_dir)
```

## ??

???????????????

```
DeepSeek-V3-0324-GGUF-Q4_K_M/
??? configuration.json              ?
??? tokenizer.json                 ?????
??? tokenizer_config.json          ?????
??? special_tokens_map.json        ?????
??? DeepSeek-V3-0324-Q4_k_m-00001-of-00009.gguf
??? DeepSeek-V3-0324-Q4_k_m-00002-of-00009.gguf
??? ...??? GGUF ???
??? README.md
```

## ????

?????????

1. **`ktransformers/local_chat.py:77`**?
   ```python
   tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
   ```
   ?????? tokenizer ???????

2. **`kt-kernel/scripts/convert_weights.py:342`**?
   ```python
   config_files = ["config.json", "tokenizer.json", "tokenizer_config.json", "special_tokens_map.json"]
   ```
   ???????????

3. **`doc/en/install.md:166`**?
   > Note: **.safetensors** files are not required in the directory. We only need config files to build model and tokenizer.

## ??

**?????????????? tokenizer ???** ??????????????????????????
